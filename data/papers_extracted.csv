authors,authors_verbatim,title,title_verbatim,journal,journal_verbatim,year,citation,abstract,abstract_verbatim,independent_variables,independent_variables_verbatim,dependent_variables,dependent_variables_verbatim,survey_questions,survey_questions_verbatim,incentive,incentive_verbatim,study_type,study_type_verbatim,analysis_equations,analysis_equations_verbatim,level_of_analysis,level_of_analysis_verbatim,main_effects,main_effects_verbatim,statistical_power,statistical_power_verbatim,moderators,moderators_verbatim,moderation_results,moderation_results_verbatim,demographics,demographics_verbatim,recruitment_source,recruitment_source_verbatim,sample_size,sample_size_verbatim,country_region,sociocultural_context,political_context,platform_technological_context,temporal_context,recommended_moderators ,research_context,intervention_insights
William J. Brady; Killian L. McLoughlin; Mark P. Torres; Kara F. Luo; Maria Gendron; M. J. Crockett,"William J. Brady 1,2 Killian L. McLoughlin2,3,4, Mark P. Torres, Kara F. Luo2, Maria Gendron² & M. J. Crockett 2,3,6",Overperception of moral outrage in online social networks inflates beliefs about intergroup hostility,Overperception of moral outrage in online social networks inflates beliefs about intergroup hostility,Nature Human Behaviour,Nature Human Behaviour,2023,"Brady, W. J., McLoughlin, K. L., Torres, M. P., Luo, K. F., Gendron, M., & Crockett, M. J. (2023). Overperception of moral outrage in online social networks inflates beliefs about intergroup hostility. Nature Human Behaviour, 7(6), 917–927.","As individuals and political leaders increasingly interact in online social networks, it is important to understand the dynamics of emotion perception online. Here, we propose that social media users overperceive levels of moral outrage felt by individuals and groups, inflating beliefs about intergroup hostility. Using a Twitter field survey, we measured authors' moral outrage in real time and compared authors' reports to observers' judgements of the authors' moral outrage. We find that observers systematically overperceive moral outrage in authors, inferring more intense moral outrage experiences from messages than the authors of those messages actually reported. This effect was stronger in participants who spent more time on social media to learn about politics. Preregistered confirmatory behavioural experiments found that overperception of individuals' moral outrage causes overperception of collective moral outrage and inflates beliefs about hostile communication norms, group affective polarization and ideological extremity. Together, these results highlight how individual-level overperceptions of online moral outrage produce collective overperceptions that have the potential to warp our social knowledge of moral and political attitudes.","As individuals and political leaders increasingly interact in online social networks, it is important to understand the dynamics of emotion perception online. Here, we propose that social media users overperceive levels of moral outrage felt by individuals and groups, inflating beliefs about intergroup hostility. Using a Twitter field survey, we measured authors' moral outrage in real time and compared authors' reports to observers' judgements of the authors' moral outrage. We find that observers systematically overperceive moral outrage in authors, inferring more intense moral outrage experiences from messages than the authors of those messages actually reported. This effect was stronger in participants who spent more time on social media to learn about politics. Preregistered confirmatory behavioural experiments found that overperception of individuals' moral outrage causes overperception of collective moral outrage and inflates beliefs about hostile communication norms, group affective polarization and ideological extremity. Together, these results highlight how individual-level overperceptions of online moral outrage produce collective overperceptions that have the potential to warp our social knowledge of moral and political attitudes.","G = Twitter conversations about contentious American political topics; H1 = Authors' moral outrage (1-7 scale: How outraged did you feel on a 1-7 scale? (1 = not at all, 4 = somewhat, 7 = very)); H2 = Observers' judgements of authors' moral outrage (same scale)","The first field study (N = 133 authors, N = 110 observers) was conducted in July and August 2020 and examined tweets discussing the William Barr Congressional hearing as well as President Trump's favourability.","O = Outrage norms, affective polarization and ideological extremity.","To examine perceptions of outrage norms, after viewing the simulated newsfeed, participants completed a norm judgement task where they were exposed to ten new political tweets that expressed political opinions with either outrage or neutral language (see Methods for details on tweet selection for this task).","1 How outraged did you feel on a 1-7 scale? (1 = not at all, 4 = somewhat, 7 = very) 2 How happy did you feel on a 1-7 scale? (1 = not at all, 4 = somewhat, 7 = very)","1 How outraged did you feel on a 1-7 scale? (1 = not at all, 4 = somewhat, 7 = very)",Award given,NOT SPECIFIED,"Experiment, Field Survey","Using a Twitter field survey, we measured authors' moral outrage in real time and compared authors' reports to observers' judgements of the authors' moral outrage.",NOT SPECIFIED,"observers reported perceiving higher levels of outrage than reported by message authors in study 1 (slope coefficient (b) = 0.59, P = 0.011, 95% confidence interval (CI) = (0.14, 1.04)) and study 2 (b = 0.58, P = 0.001, 95% CI = (0.25, 0.92))","observers reported perceiving higher levels of outrage than reported by message authors in study 1 (slope coefficient (b) = 0.59, P = 0.011, 95% confidence interval (CI) = (0.14, 1.04)) and study 2 (b = 0.58, P = 0.001, 95% CI = (0.25, 0.92))",Individual,"observers reported higher levels of outrage than reported by message authors in study 1 (slope coefficient (b) = 0.59, P = 0.011, 95% confidence interval (CI) = (0.14, 1.04)) and study 2 (b = 0.58, P = 0.001, 95% CI = (0.25, 0.92))",NOT SPECIFIED,NOT SPECIFIED,Political social media use,"Consistent with this reasoning, we found a significant positive correlation between overperception of outrage and political social media use (r(222) = 0.19, P = 0.004, 95% CI = (0.06, 0.31))","To examine perceptions of outrage norms, after viewing the simulated newsfeed, participants completed a norm judgement task where they were exposed to ten new political tweets that expressed political opinions with either outrage or neutral language (see Methods for details on tweet selection for this task). We found that participants exposed to the high-overperception newsfeed judged tweets that expressed outrage as more socially appropriate (relative to more neutral tweets) than participants who were exposed to the low-overperception newsfeed, t(964.58) = -6.89, P < 0.001, d = 0.43, 95% CI = (0.47, 0.85) (Fig. 5; Methods). Thus, viewing a newsfeed that produced overperception of collective outrage amplified people's perceptions of how normative it is to express outrage in the social network.","To examine perceptions of outrage norms, after viewing the simulated newsfeed, participants completed a norm judgement task where they were exposed to ten new political tweets that expressed political opinions with either outrage or neutral language (see Methods for details on tweet selection for this task).","Age, gender, political leaning, SES","Study 4 age: M = 35.61, SD = 13.33; 55% Female; Study 5 age: M = 36.95, SD = 13.94, 52% Female.","Prolific, MTurk","We chose the Prolific platform because it tends to have better data quality (e.g., higher response rates and comprehension checks) than MTurk and enforces better pay standards.","133 authors, N = 110 observers, N = 200 authors, N = 190 observers, N = 600, N = 1,200, N = 350","The first field study (N = 133 authors, N = 110 observers) was conducted in July and August 2020 and examined tweets discussing the William Barr Congressional hearing as well as President Trump's favourability.",USA,NOT SPECIFIED,"Election cycle, contentious events",Twitter,2020,NOT SPECIFIED,NOT SPECIFIED,Correcting people's ingroup perceptions by providing more accurate social information may combat overperception of outrage expression.,NOT SPECIFIED
Sze-Yuh Nina Wang; Yoel Inbar,"Department of Psychology, University of Toronto",Re-Examining the Spread of Moralized Rhetoric From Political Elites: Effects of Valence and Ideology,Re-Examining the Spread of Moralized Rhetoric From Political Elites: Effects of Valence and Ideology,Journal of Experimental Psychology: General,Journal of Experimental Psychology: General,2022,"Wang, S.-Y. N., & Inbar, Y. (2022). Re-Examining the Spread of Moralized Rhetoric From Political Elites: Effects of Valence and Ideology. Journal of Experimental Psychology: General, 151(12), 3292–3303. https://doi.org/10.1037/xge0001247","We examine the robustness of previous research finding increased diffusion of Twitter messages (“tweets”) containing moral rhetoric. We use a distributed language model to examine the moral lan- guage used by U.S. political elites in two corpora of tweets: one from 2016 presidential candidates Hillary Clinton and Donald Trump, and one from U.S. Members of Congress. Consistent with previous research, we find greater diffusion for tweets containing moral rhetoric, but this is qualified by moral language valence and elite ideology. For both presidential candidates and Members of Congress, nega- tive moral language is associated with increased message diffusion. Positive moral language is not asso- ciated with diffusion for presidential candidates and is negatively associated with diffusion for Members of Congress. In both data sets, the relationship between negative moral language and message diffusion is stronger for liberals than conservatives.","We examine the robustness of previous research finding increased diffusion of Twitter messages (“tweets”) containing moral rhetoric. We use a distributed language model to examine the moral lan- guage used by U.S. political elites in two corpora of tweets: one from 2016 presidential candidates Hillary Clinton and Donald Trump, and one from U.S. Members of Congress. Consistent with previous research, we find greater diffusion for tweets containing moral rhetoric, but this is qualified by moral language valence and elite ideology. For both presidential candidates and Members of Congress, nega- tive moral language is associated with increased message diffusion. Positive moral language is not asso- ciated with diffusion for presidential candidates and is negatively associated with diffusion for Members of Congress. In both data sets, the relationship between negative moral language and message diffusion is stronger for liberals than conservatives.","G = Moral rhetoric, Valence; H = Positive moral language (virtue) terms (authority, obey, respect, tradition, purity, sanctity, sacred, wholesome, loyal, solidarity, patriot, fidelity, kindness, compassion, nurture, empathy, fairness, equality, justice, rights), Negative moral language (vice) terms (impurity, depravity, degradation, unnatural, betray, treason, disloyal, traitor, cheat, fraud, unfair, injustice, subversion, disobey, disrespect, chaos, suffer, cruel, hurt, harm)","Department of Psychology, University of Toronto","Message diffusion, log-transformed retweet counts","Message diffusion, log-transformed retweet counts",NOT SPECIFIED,NOT SPECIFIED,NOT SPECIFIED,NOT SPECIFIED,Experiment,Experiment,"For the Clinton-Trump dataset, we used OLS regression and dummy-coded tweet author (Clinton or Trump). For our analyses of tweets from Members of Congress, we used multilevel linear models, nesting tweets within accounts to model nonindependence between tweets from the same account.","For the Clinton-Trump dataset, we used OLS regression and dummy-coded tweet author (Clinton or Trump). For our analyses of tweets from Members of Congress, we used multilevel linear models, nesting tweets within accounts to model nonindependence between tweets from the same account.","Individual, Tweet","Individual, Tweet","Negative moral language significantly predicts retweets, while positive moral language does not.","Negative moral language significantly predicts retweets, while positive moral language does not.",NOT SPECIFIED,NOT SPECIFIED,Legislator ideology (DW-NOMINATE scores),Legislator ideology (DW-NOMINATE scores),"Tweets with more negative moral language were retweeted more regardless of legislator ideology, but this effect was stronger for more liberal legislators","Tweets with more negative moral language were retweeted more regardless of legislator ideology, but this effect was stronger for more liberal legislators",Clinton-Trump dataset: N/A. Congressional dataset: DW-NOMINATE scores (higher numbers correspond to a more conservative voting record).,Clinton-Trump dataset: N/A. Congressional dataset: DW-NOMINATE scores (higher numbers correspond to a more conservative voting record).,Brady et al. (2019),Brady et al. (2019),"Clinton-Trump dataset: 9,505 tweets. Congressional dataset: 687,360 tweets.","Clinton-Trump dataset: 9,505 tweets. Congressional dataset: 687,360 tweets.",USA,NOT SPECIFIED,The Democrats had suffered a shocking loss in the presidential election and held neither the Senate nor the House of Representatives,Twitter,2016 to 2018,Threat,NOT SPECIFIED,NOT SPECIFIED
Brendan Nyhan; Jaime Settle; Emily Thorson; Magdalena Wojcieszak; Pablo Barberá; Annie Y. Chen; Hunt Allcott; Taylor Brown; Adriana Crespo-Tenorio; Drew Dimmery; Deen Freelon; Matthew Gentzkow; Sandra González-Bailón; Andrew M. Guess; Edward Kennedy; Young Mie Kim; David Lazer; Neil Malhotra; Devra Moehler; Jennifer Pan; Daniel Robert Thomas; Rebekah Tromble; Carlos Velasco Rivera; Arjun Wilkins; Beixian Xiong; Chad Kiewiet de Jonge; Annie Franco; Winter Mason; Natalie Jomini Stroud & Joshua A. Tucker,"Brendan Nyhan 1,25, Jaime Settle 2,25, Emily Thorson 3,25, Magdalena Wojcieszak 4,5,25, Pablo Barberá 6,25, Annie Y. Chen7, Hunt Allcott8, Taylor Brown9, Adriana Crespo-Tenorio6, Drew Dimmery 6,24, Deen Freelon9, Matthew Gentzkow¹⁰, Sandra González-Bailón, Andrew M. Guess 11,12, Edward Kennedy 13, Young Mie Kim14, David Lazer 15, Neil Malhotra 16, Devra Moehler, Jennifer Pan¹",Like-minded sources on Facebook are prevalent but not polarizing,Like-minded sources on Facebook are prevalent but not polarizing,Nature,Nature,2023,"Nyhan, B., Settle, J., Thorson, E., Wojcieszak, M., Barberá, P., Chen, A. Y., Allcott, H., Brown, T., Crespo-Tenorio, A., Dimmery, D., Freelon, D., Gentzkow, M., González-Bailón, S., Guess, A. M., Kennedy, E., Kim, Y. M., Lazer, D., Malhotra, N., Moehler, D., Pan, J., Thomas, D. R., Tromble, R., Velasco Rivera, C., Wilkins, A., Xiong, B., Kiewiet de Jonge, C., Franco, A., Mason, W., Stroud, N. J., & Tucker, J. A. (2023). Like-minded sources on Facebook are prevalent but not polarizing. Nature, 620(7972), 137-144.","Many critics raise concerns about the prevalence of 'echo chambers' on social media and their potential role in increasing political polarization. However, the lack of available data and the challenges of conducting large-scale field experiments have made it difficult to assess the scope of the problem¹2. Here we present data from 2020 for the entire population of active adult Facebook users in the USA showing that content from 'like-minded' sources constitutes the majority of what people see on the platform, although political information and news represent only a small fraction of these exposures. To evaluate a potential response to concerns about the effects of echo chambers, we conducted a multi-wave field experiment on Facebook among 23,377 users for whom we reduced exposure to content from like-minded sources during the 2020 US presidential election by about one-third. We found that the intervention increased their exposure to content from cross-cutting sources and decreased exposure to uncivil language, but had no measurable effects on eight preregistered attitudinal measures such as affective polarization, ideological extremity, candidate evaluations and belief in false claims. These precisely estimated results suggest that although exposure to content from like-minded sources on social media is common, reducing its prevalence during the 2020 US presidential election did not correspondingly reduce polarization in beliefs or attitudes.","Many critics raise concerns about the prevalence of 'echo chambers' on social media and their potential role in increasing political polarization. However, the lack of available data and the challenges of conducting large-scale field experiments have made it difficult to assess the scope of the problem¹2. Here we present data from 2020 for the entire population of active adult Facebook users in the USA showing that content from 'like-minded' sources constitutes the majority of what people see on the platform, although political information and news represent only a small fraction of these exposures. To evaluate a potential response to concerns about the effects of echo chambers, we conducted a multi-wave field experiment on Facebook among 23,377 users for whom we reduced exposure to content from like-minded sources during the 2020 US presidential election by about one-third. We found that the intervention increased their exposure to content from cross-cutting sources and decreased exposure to uncivil language, but had no measurable effects on eight preregistered attitudinal measures such as affective polarization, ideological extremity, candidate evaluations and belief in false claims. These precisely estimated results suggest that although exposure to content from like-minded sources on social media is common, reducing its prevalence during the 2020 US presidential election did not correspondingly reduce polarization in beliefs or attitudes.","G = ""Content from like-minded sources""; H = reduced exposure to content from friends, groups and Pages that were predicted to share the participant's political leaning.","For participants assigned to treatment, we downranked all content (including, but not limited to, civic and news content) from friends, groups and Pages that were predicted to share the participant's political leaning (for example, all content from conservative friends and groups and Pages with conservative audiences was downranked for participants classified as conservative; see Supplementary Information, section 1.1).","A = ""Affective polarization""; B = ""Ideological extremity""; C = ""Ideologically consistent issue positions, group evaluations and vote choice and candidate evaluations""; D = ""Partisan-congenial beliefs and views about election misconduct and outcomes, views toward the electoral system and respect for election norms""","Finally, we examine the causal effects of reducing exposure to like-minded sources on Facebook on a range of attitudinal outcomes measured in post-election surveys (Fig. 3d).",NOT SPECIFIED,NOT SPECIFIED,Participants were given the option to withdraw from the study while the experiment was ongoing as well as to withdraw their data at any time up until their survey responses were disconnected from any identifying information in February 2023.,Participants were given the option to withdraw from the study while the experiment was ongoing as well as to withdraw their data at any time up until their survey responses were disconnected from any identifying information in February 2023.,Field experiment,"Here we present data from 2020 for the entire population of active adult Facebook users in the USA showing that content from 'like-minded' sources constitutes the majority of what people see on the platform, although political information and news represent only a small fraction of these exposures.","Treatment effect estimates use OLS with robust standard errors and control for covariates selected using the least absolute shrinkage and selection operator47 (see Supplementary Information, section 1.5.1).","Treatment effect estimates use OLS with robust standard errors and control for covariates selected using the least absolute shrinkage and selection operator47 (see Supplementary Information, section 1.5.1).",Individual; Treatment substantially reduced exposure to content from like-minded sources relative to the pre-treatment period. Average exposure to content from like-minded sources declined to 36.2% in the treatment group while remaining stable at 53.7% in the control group (P<0.01).,"As intended, the treatment substantially reduced exposure to content from like-minded sources relative to the pre-treatment period.","reduction in exposure to content from like-minded sources from 53.7% to 36.2% represents a difference of 0.77 s.d. (95% confidence interval: -0.80, -0.75).","reduction in exposure to content from like-minded sources from 53.7% to 36.2% represents a difference of 0.77 s.d. (95% confidence interval: -0.80, -0.75).",designed the study to provide statistical power to detect small effects.,We designed the study to provide statistical power to detect small effects.,"political ideology (direction or extremity), political sophistication, digital literacy, pre-treatment exposure to content that is political, and pre-treatment levels of like-minded exposure both as a proportion of respondents' information diet and as the total number of exposures","Finally, we examine heterogeneous treatment effects on the attitudes reported in Fig. 3d and the research questions across a number of preregistered characteristics: respondents' political ideology (direction or extremity), political sophistication, digital literacy, pre-treatment exposure to content that is political, and pre-treatment levels of like-minded exposure both as a proportion of respondents' information diet and as the total number of exposures (see Supplementary Information, section 3.9).",None of the 272 preregistered subgroup treatment effect estimates for our primary outcomes are statistically significant after adjustment to control the false discovery rate.,None of the 272 preregistered subgroup treatment effect estimates for our primary outcomes are statistically significant after adjustment to control the false discovery rate.,"73.3% white, 57.3% female, relatively highly educated (50.7% have a college degree), and 54.1% self-identify as Democrats or lean Democrat","Participants in our field experiment are 73.3% white, 57.3% female, relatively highly educated (50.7% have a college degree), and 54.1% self-identify as Democrats or lean Democrat.",Recruited via survey invitations placed at the top of their Facebook feeds,Participants in the treatment and control groups were invited to complete five surveys before and after the 2020 presidential election assessing their political attitudes and behaviours.,"23,377","In total, the sample for this study consists of 23,377 US-based adult Facebook users who were recruited via survey invitations placed at the top of their Facebook feeds in August and September 2020, provided informed consent to participate and completed at least one post-election survey wave (see Supplementary Information, sections 4.5 and 4.9).",USA,NOT SPECIFIED,US 2020 presidential election,Facebook,2020,NOT SPECIFIED,NOT SPECIFIED,"Changes to social media algorithms can have marked effects on the content that users see, and can reduce exposure to uncivil content and misinformation."
Elizabeth Suhay; Emily Bello-Pardo; Brianna Maurer,SSAGE,The Polarizing Effects of Online Partisan Criticism: Evidence from Two Experiments,The Polarizing Effects of Online Partisan Criticism: Evidence from Two Experiments,The International Journal of Press/Politics,The International Journal of Press/Politics,2018,"Suhay, E., Bello-Pardo, E., & Maurer, B. (2018). The Polarizing Effects of Online Partisan Criticism: Evidence from Two Experiments. The International Journal of Press/Politics, 23(1), 95–115.","Affective and social political polarization—a dislike of political opponents and a desire to avoid their company—are increasingly salient and pervasive features of politics in many Western democracies, particularly the United States. One contributor to these related phenomena may be increasing exposure to online political disagreements in which ordinary citizens criticize, and sometimes explicitly demean, opponents. This article presents two experimental studies that assessed whether U.S. partisans' attitudes became more prejudiced in favor of the in-party after exposure to online partisan criticism. In the first study, we draw on an online convenience sample to establish that partisan criticism that derogates political opponents increases affective polarization. In the second, we replicate these findings with a quasi-representative sample and extend the pattern of findings to social polarization. We conclude that online partisan criticism likely has contributed to rising affective and social polarization in recent years between Democrats and Republicans in the United States, and perhaps between partisan and ideological group members in other developed democracies as well. We close by discussing the troubling implications of these findings in light of continuing attempts by autocratic regimes and other actors to influence democratic elections via false identities on social media.","Abstract Affective and social political polarization—a dislike of political opponents and a desire to avoid their company—are increasingly salient and pervasive features of politics in many Western democracies, particularly the United States. One contributor to these related phenomena may be increasing exposure to online political disagreements in which ordinary citizens criticize, and sometimes explicitly demean, opponents. This article presents two experimental studies that assessed whether U.S. partisans' attitudes became more prejudiced in favor of the in-party after exposure to online partisan criticism. In the first study, we draw on an online convenience sample to establish that partisan criticism that derogates political opponents increases affective polarization. In the second, we replicate these findings with a quasi-representative sample and extend the pattern of findings to social polarization. We conclude that online partisan criticism likely has contributed to rising affective and social polarization in recent years between Democrats and Republicans in the United States, and perhaps between partisan and ideological group members in other developed democracies as well. We close by discussing the troubling implications of these findings in light of continuing attempts by autocratic regimes and other actors to influence democratic elections via false identities on social media.","G = ""anti-Democrat incivility""; H = ""anti-Republican incivility""; G = ""anti-Democrat criticism""; H = ""anti-Republican criticism""",Treatment,"Affective polarization, Social polarization (interparty marriage, interparty social segregation), Approval of Obama (study 1 only)",Outcome,"Feeling Thermometer: Please rate each group below using something we call the feeling thermometer. Ratings between 50 degrees and 100 degrees mean that you feel favorable and warm toward the group. Ratings between 0 degrees and 50 degrees mean that you don't feel favorable toward the group or that you don't care too much for that group. You would rate the group at the 50 degree mark if you don't feel particularly warm or cold toward the group. You may choose any number between (and including) 0 and 100. Use the slider to indicate your rating. Your rating will be displayed toward the right of each category. How do you think you would react if a member of your family told you they were going to marry a Republican? Would you be... How do you think you would react if a member of your family told you they were going to marry a Democrat? Would you be... Imagine for a moment that you are moving to another community...In deciding where to live, how important would it be to live in a place where most people held political views similar to your own?",Dependent Variable Wording,Monetary compensation,Timing” requirements are one way to ensure that the analytical sample is exposed to the stimulus (Berinsky et al. 2012).,Experiment,Sample and study design.,OLS regression,Note: Ordinary Least Squares regression. Numbers in parentheses are standard errors. Party ID coded - I to I with Republicans receiving higher scores.,Individual,Ordinary least squares regression. Numbers in parentheses are standard errors. Party ID coded -1 to I with Republicans receiving higher scores. FT = feeling thermometer.,"Study 1: The coefficient on the anti-Republican term is significant at p < .05 (bAntiRepXPID = .102); the coefficient on the anti-Democratic term does not reach standard thresholds for statistical signifi- cance. Study 2: The coefficients on the Anti-Republican interaction terms are positive and signifi- cant in both models (bAntiRepXPID = .105, b AntiRepXPID = .08; p < .05); however, the Anti- Democratic interaction terms are close to zero (and not significant).",Study I). FT = feeling thermometer; Cl = confidence interval.,NOT SPECIFIED,NOT SPECIFIED,NOT SPECIFIED,NOT SPECIFIED,NOT SPECIFIED,"Again, the additional stimuli received by treated participants (relative to the control group) are highlighted in gray.","Age, Gender, Race, Party Identification","In the pre-test, we measured age, gender, race, and party as key pre-treatment covariates across the treatment groups.","Amazon Mechanical Turk (AMT), Qualtrics Panels",Sample and study design.,424; 542,AMT) (N = 424) ... Qualtrics Panels (N = 542).,United States,NOT SPECIFIED,NOT SPECIFIED,Comment sections of news websites,"2013, 2015",NOT SPECIFIED,NOT SPECIFIED,"Fanning the flames of existing inter-party animosity has been one method of accomplishing these ends. This phenomenon is not limited to Russia as perpetrator or the United States as victim, of course, with governments around the world employing such tactics against citizens in other nations as well as their own"
Alexander Bor; Michael Bang Petersen,"Social media has created a unique ecosystem charac terized by “a personalized, quantified blend of politic ally informative expression, news, and discussion that is seamlessly interwoven with non-political content”","The Psychology of Online Political Hostility: A Comprehensive, Cross-National Test of the Mismatch Hypothesis","The Psychology of Online Political Hostility: A Comprehensive, Cross-National Test of the Mismatch Hypothesis",American Political Science Review,American Political Science Review,2022,"Bor, A., & Petersen, M. B. (2022). The Psychology of Online Political Hostility: A Comprehensive, Cross-National Test of the Mismatch Hypothesis. American Political Science Review, 116(1), 1-18.","Why are online discussions about politics more hostile than offline discussions? A popular answer argues that human psychology is tailored for face-to-face interaction and people's behavior therefore changes for the wo worse in impersonal online discussions. We provide a theoretical formalization and empirical test of this explanation: the mismatch hypothesis. We argue that mismatches between human psychology and novel features of online environments could (a) change people's behavior, (b) create adverse selection effects, and (c) bias people's perceptions. Across eight studies, leveraging cross-national surveys and behavioral experiments (total N = 8,434), we test the mismatch hypothesis but only find evidence for limited selection effects. Instead, hostile political discussions are the result of status-driven individuals who are drawn to politics and are equally hostile both online and offline. Finally, we offer initial evidence that online discussions feel more hostile, in part, because the behavior of such individuals is more visible online than offline.","Why are online discussions about politics more hostile than offline discussions? A popular answer argues that human psychology is tailored for face-to-face interaction and people's behavior therefore changes for the wo worse in impersonal online discussions. We provide a theoretical formalization and empirical test of this explanation: the mismatch hypothesis. We argue that mismatches between human psychology and novel features of online environments could (a) change people's behavior, (b) create adverse selection effects, and (c) bias people's perceptions. Across eight studies, leveraging cross-national surveys and behavioral experiments (total N = 8,434), we test the mismatch hypothesis but only find evidence for limited selection effects. Instead, hostile political discussions are the result of status-driven individuals who are drawn to politics and are equally hostile both online and offline. Finally, we offer initial evidence that online discussions feel more hostile, in part, because the behavior of such individuals is more visible online than offline.","G = ""online versus offline political discussions""; H = ""Political discussions occur on the Internet, including social media and comments sections"" or ""face-to-face""","We contend that any framework for explaining the hostility gap, and other potential differences between online and offline behavior and perceptions, needs to","O = ""Perceptions of hostility in online and offline discussions""",We define political hostility as the use of intimidation in political discussions and ask why people experience more political hostility in online versus offline discussions.,"G = Whether these discussions are perceived to be aggressive, uncivil, and hostile and how often these things happen to them online, vs offline",Our main dependent variable for testing the change hypothesis is self-reported hostility in online and offline discussions.,Award amount = $1.50,Participants gave informed consent (see OA Section F) and were reimbursed with $1.50.,Mixed methods,"Instead, we rely on other study designs: Studies 1–4 present a series of approximately representative online surveys in which we observe the same individuals' experiences with political hostility in both online and offline contexts. In these within-subject designs, we also examine how a primary psychological trait (specifically, individual differences in status-seeking) relates to pol itical hostility.","Equation: OLS regressions. All variables are scaled to 0-1. Models adjust for basic demographic covariates: age, gender, education, and income in both countries; a standard seven-point partisan identity scale in the US; a three-level (red-block, blue-block, or neither) partisanship variable in Denmark; and also an indicator for identifying as white in the United States. Formal tests for the statistical significance of the differences in coefficients rely on structural equation models.","All anonymized data, scripts, and materials that are necessary to replicate and reproduce our findings are available at the American Political Science Review Dataverse (Bor and Petersen 2021).",Individual,"Research on the psychological roots of dominance reveals that ""induc[ing] fear, through intimidation and coercion"" is a primary strategy for attaining status (Cheng et al. 2013, 105), and one of the most consistent psychological findings is that individuals preoccupied with attaining higher status are much more likely to commit aggressive and hostile acts (including homicide) in everyday life (Wilson and Daly 1985). Recent research has extended this to the political domain and found that status-seeking (both at the individual and the group-level) is a strong empirical predictor of support for and engagement in aggression, even violence, for a political cause around the world (Bartusevičius, van Leeuwen, and Petersen 2020; see also Kalmoe 2014). As summarized by Bartusevičius, van Leeuwen, and Petersen (2020) status-seeking is “a-if not the-key predictor of disruptive political behavior.”",Individuals preoccupied with attaining higher status are much more likely to commit aggressive and hostile acts,NOT SPECIFIED,"To test the selection hypothesis, we focus on the most basic observable implication: individuals who are motivated to engage in hostility-as captured by indi-vidual differences in status seeking-are more likely to engage in online than in offline political discussions.","If status-oriented traits are highly and equally predictive of hostility across con-texts, this may imply that connectivity rather than mismatch effects lie at the heart of the hostility gap.",Not.,"As is clear from this discussion, the mismatch and the connectivity explanations for online political hostility may, to some extent, be pitted against each other using the classical psychological distinction between states (i.e., ephemeral, context-induced motivations) versus traits (i.e., stable motivations grounded in personality)","Age, gender, education, income, partisan identity, race.","Unless otherwise noted, our models adjust (or ""control"") for basic demographic covariates: age, gender, education, and income in both countries; a standard seven-point partisan identity scale in the US; a three-level (red-block, blue-block, or neither) partisanship variable in Denmark; and also an indicator for identifying as white in the United States.",YouGov; Lucid; Amazon Mechanical Turk,We collected data through YouGov and Lucid and fielded online surveys to approximately nationally rep resentative samples of Americans and Danes.,"N = 8,434 (total); N = 1,515 (Study 1); N = 1,434 (Study 2); N = 998 (Study 3); N = 1,317 (Study 4 and 5); N = 2,137 (Study 6); N = 2,089 (Study 7)","A total of 1,317 American adults were interviewed by YouGov and selected via quota sampling to ensure resemblance of the population.",United States and Denmark,"The United States is a high-polarization, high-conflict, low-trust, low-participation country, whereas Denmark is a low-polarization, low-conflict, high-trust, high-participation country (Nelson and Shavitt 2002).",NOT SPECIFIED,"Online environments are unique in creating large public forums, where hostile messages may reach thousands including many strangers, could stay access ible perennially, and may be promoted by algorithms tuned to generate interactions (Brady, Crockett, and Van Bavel 2020; Ribeiro et al. 2019; Settle 2018).",2020-2021; COVID-19 pandemic,"Future studies should assess whether mismatches could propel hostility in specific environments, platforms, or situations, even if these mismatches do not generate hostility in all online environments.",NOT SPECIFIED,Policies against hostility should seek to reduce the connectivity of hostile individuals. Norms of civility are somewhat weaker online than offline and continued exposure to hostile messages may increase this gap.,NOT SPECIFIED,NOT SPECIFIED